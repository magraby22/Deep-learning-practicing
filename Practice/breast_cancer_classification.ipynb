{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd6e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e78de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "breastCancerData = load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3c8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "print (breastCancerData.data.shape ,  breastCancerData.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ed16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print (breastCancerData.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb27b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cancer_data = pd.DataFrame(breastCancerData.data ,columns=breastCancerData.feature_names)\n",
    "Cancer_data[\"diagnosis\"] = pd.Series(breastCancerData.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75be4ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  diagnosis                569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "Cancer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35b0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Cancer_data.drop(['diagnosis'],axis=1)\n",
    "target = Cancer_data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e1d5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "scaled_feutures = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe7dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_feutures, \n",
    "                       target, test_size= 0.20, random_state=100, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab14c586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =  (455, 30)  y_train =  (455,)\n",
      "X_test  =  (114, 30)  y_test  =  (114,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train = \",X_train.shape ,\" y_train = \", y_train.shape)\n",
    "print(\"X_test  = \",X_test.shape ,\" y_test  = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5085e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,537</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,537\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,537</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,537\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(32,  activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115e14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08622ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.3984 - loss: 0.8510 - val_accuracy: 0.5495 - val_loss: 0.7587\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6374 - loss: 0.6613 - val_accuracy: 0.6923 - val_loss: 0.6043\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7692 - loss: 0.5233 - val_accuracy: 0.7582 - val_loss: 0.4914\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8214 - loss: 0.4276 - val_accuracy: 0.8132 - val_loss: 0.4105\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8489 - loss: 0.3574 - val_accuracy: 0.8462 - val_loss: 0.3520\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8819 - loss: 0.3068 - val_accuracy: 0.8791 - val_loss: 0.3076\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8984 - loss: 0.2680 - val_accuracy: 0.9011 - val_loss: 0.2746\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9011 - loss: 0.2362 - val_accuracy: 0.9011 - val_loss: 0.2488\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9176 - loss: 0.2122 - val_accuracy: 0.9011 - val_loss: 0.2281\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9203 - loss: 0.1921 - val_accuracy: 0.9011 - val_loss: 0.2112\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9341 - loss: 0.1755 - val_accuracy: 0.9121 - val_loss: 0.1971\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9368 - loss: 0.1631 - val_accuracy: 0.9121 - val_loss: 0.1851\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9423 - loss: 0.1523 - val_accuracy: 0.9121 - val_loss: 0.1747\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9505 - loss: 0.1434 - val_accuracy: 0.9121 - val_loss: 0.1660\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9560 - loss: 0.1352 - val_accuracy: 0.9231 - val_loss: 0.1582\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9588 - loss: 0.1282 - val_accuracy: 0.9231 - val_loss: 0.1512\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9588 - loss: 0.1226 - val_accuracy: 0.9231 - val_loss: 0.1448\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9588 - loss: 0.1170 - val_accuracy: 0.9341 - val_loss: 0.1398\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9643 - loss: 0.1122 - val_accuracy: 0.9341 - val_loss: 0.1351\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9643 - loss: 0.1078 - val_accuracy: 0.9451 - val_loss: 0.1308\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9643 - loss: 0.1040 - val_accuracy: 0.9451 - val_loss: 0.1272\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9670 - loss: 0.1004 - val_accuracy: 0.9451 - val_loss: 0.1246\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9753 - loss: 0.0973 - val_accuracy: 0.9451 - val_loss: 0.1222\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0940 - val_accuracy: 0.9451 - val_loss: 0.1195\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0912 - val_accuracy: 0.9451 - val_loss: 0.1166\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9753 - loss: 0.0884 - val_accuracy: 0.9451 - val_loss: 0.1146\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9780 - loss: 0.0859 - val_accuracy: 0.9451 - val_loss: 0.1121\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9780 - loss: 0.0835 - val_accuracy: 0.9451 - val_loss: 0.1106\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9780 - loss: 0.0813 - val_accuracy: 0.9451 - val_loss: 0.1091\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9808 - loss: 0.0789 - val_accuracy: 0.9451 - val_loss: 0.1078\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9808 - loss: 0.0770 - val_accuracy: 0.9451 - val_loss: 0.1055\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9808 - loss: 0.0748 - val_accuracy: 0.9451 - val_loss: 0.1039\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9808 - loss: 0.0731 - val_accuracy: 0.9560 - val_loss: 0.1030\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9808 - loss: 0.0713 - val_accuracy: 0.9560 - val_loss: 0.1013\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9808 - loss: 0.0697 - val_accuracy: 0.9560 - val_loss: 0.0995\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9808 - loss: 0.0678 - val_accuracy: 0.9560 - val_loss: 0.0984\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9835 - loss: 0.0663 - val_accuracy: 0.9560 - val_loss: 0.0970\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9835 - loss: 0.0649 - val_accuracy: 0.9560 - val_loss: 0.0959\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9835 - loss: 0.0635 - val_accuracy: 0.9560 - val_loss: 0.0950\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9863 - loss: 0.0621 - val_accuracy: 0.9560 - val_loss: 0.0940\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9863 - loss: 0.0608 - val_accuracy: 0.9560 - val_loss: 0.0927\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9863 - loss: 0.0595 - val_accuracy: 0.9560 - val_loss: 0.0917\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9863 - loss: 0.0583 - val_accuracy: 0.9560 - val_loss: 0.0910\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9890 - loss: 0.0571 - val_accuracy: 0.9560 - val_loss: 0.0904\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9890 - loss: 0.0560 - val_accuracy: 0.9670 - val_loss: 0.0902\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0549 - val_accuracy: 0.9670 - val_loss: 0.0899\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0540 - val_accuracy: 0.9670 - val_loss: 0.0897\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0528 - val_accuracy: 0.9670 - val_loss: 0.0891\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9918 - loss: 0.0519 - val_accuracy: 0.9670 - val_loss: 0.0891\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0511 - val_accuracy: 0.9670 - val_loss: 0.0880\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0501 - val_accuracy: 0.9670 - val_loss: 0.0872\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9918 - loss: 0.0492 - val_accuracy: 0.9670 - val_loss: 0.0875\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0484 - val_accuracy: 0.9670 - val_loss: 0.0873\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0475 - val_accuracy: 0.9670 - val_loss: 0.0874\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0467 - val_accuracy: 0.9670 - val_loss: 0.0872\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0460 - val_accuracy: 0.9670 - val_loss: 0.0870\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0453 - val_accuracy: 0.9670 - val_loss: 0.0865\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0445 - val_accuracy: 0.9670 - val_loss: 0.0857\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0439 - val_accuracy: 0.9670 - val_loss: 0.0860\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0431 - val_accuracy: 0.9670 - val_loss: 0.0856\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0424 - val_accuracy: 0.9670 - val_loss: 0.0847\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0416 - val_accuracy: 0.9670 - val_loss: 0.0844\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0409 - val_accuracy: 0.9670 - val_loss: 0.0838\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0401 - val_accuracy: 0.9670 - val_loss: 0.0836\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0394 - val_accuracy: 0.9670 - val_loss: 0.0829\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0389 - val_accuracy: 0.9670 - val_loss: 0.0835\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0382 - val_accuracy: 0.9560 - val_loss: 0.0839\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0374 - val_accuracy: 0.9560 - val_loss: 0.0829\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0369 - val_accuracy: 0.9560 - val_loss: 0.0822\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0361 - val_accuracy: 0.9560 - val_loss: 0.0825\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0354 - val_accuracy: 0.9560 - val_loss: 0.0828\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0348 - val_accuracy: 0.9560 - val_loss: 0.0833\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0342 - val_accuracy: 0.9560 - val_loss: 0.0834\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0336 - val_accuracy: 0.9560 - val_loss: 0.0834\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0330 - val_accuracy: 0.9560 - val_loss: 0.0835\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9918 - loss: 0.0325 - val_accuracy: 0.9560 - val_loss: 0.0835\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9918 - loss: 0.0318 - val_accuracy: 0.9560 - val_loss: 0.0840\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9918 - loss: 0.0313 - val_accuracy: 0.9560 - val_loss: 0.0840\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0307 - val_accuracy: 0.9560 - val_loss: 0.0842\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0301 - val_accuracy: 0.9560 - val_loss: 0.0841\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0295 - val_accuracy: 0.9560 - val_loss: 0.0838\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0289 - val_accuracy: 0.9560 - val_loss: 0.0844\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0285 - val_accuracy: 0.9560 - val_loss: 0.0849\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0279 - val_accuracy: 0.9560 - val_loss: 0.0847\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0273 - val_accuracy: 0.9560 - val_loss: 0.0847\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0268 - val_accuracy: 0.9560 - val_loss: 0.0851\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0264 - val_accuracy: 0.9560 - val_loss: 0.0855\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0260 - val_accuracy: 0.9560 - val_loss: 0.0855\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0254 - val_accuracy: 0.9560 - val_loss: 0.0855\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0250 - val_accuracy: 0.9560 - val_loss: 0.0855\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9945 - loss: 0.0245 - val_accuracy: 0.9560 - val_loss: 0.0857\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0241 - val_accuracy: 0.9560 - val_loss: 0.0852\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0236 - val_accuracy: 0.9560 - val_loss: 0.0854\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9945 - loss: 0.0233 - val_accuracy: 0.9560 - val_loss: 0.0859\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0228 - val_accuracy: 0.9560 - val_loss: 0.0853\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0224 - val_accuracy: 0.9560 - val_loss: 0.0855\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0220 - val_accuracy: 0.9560 - val_loss: 0.0854\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0215 - val_accuracy: 0.9560 - val_loss: 0.0861\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0212 - val_accuracy: 0.9560 - val_loss: 0.0866\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9945 - loss: 0.0207 - val_accuracy: 0.9560 - val_loss: 0.0853\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f27ee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.39835163950920105,\n",
       "  0.6373626589775085,\n",
       "  0.7692307829856873,\n",
       "  0.8214285969734192,\n",
       "  0.848901093006134,\n",
       "  0.8818681240081787,\n",
       "  0.8983516693115234,\n",
       "  0.901098906993866,\n",
       "  0.9175823926925659,\n",
       "  0.9203296899795532,\n",
       "  0.9340659379959106,\n",
       "  0.9368131756782532,\n",
       "  0.942307710647583,\n",
       "  0.9505494236946106,\n",
       "  0.9560439586639404,\n",
       "  0.958791196346283,\n",
       "  0.958791196346283,\n",
       "  0.958791196346283,\n",
       "  0.9642857313156128,\n",
       "  0.9642857313156128,\n",
       "  0.9642857313156128,\n",
       "  0.9670329689979553,\n",
       "  0.9752747416496277,\n",
       "  0.9752747416496277,\n",
       "  0.9752747416496277,\n",
       "  0.9752747416496277,\n",
       "  0.9780219793319702,\n",
       "  0.9780219793319702,\n",
       "  0.9780219793319702,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9835164546966553,\n",
       "  0.9835164546966553,\n",
       "  0.9835164546966553,\n",
       "  0.9862637519836426,\n",
       "  0.9862637519836426,\n",
       "  0.9862637519836426,\n",
       "  0.9862637519836426,\n",
       "  0.9890109896659851,\n",
       "  0.9890109896659851,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9917582273483276,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702,\n",
       "  0.9945054650306702],\n",
       " 'loss': [0.8509678840637207,\n",
       "  0.6613218784332275,\n",
       "  0.5233350396156311,\n",
       "  0.42760610580444336,\n",
       "  0.3574429750442505,\n",
       "  0.3067580759525299,\n",
       "  0.26804235577583313,\n",
       "  0.23621372878551483,\n",
       "  0.21224118769168854,\n",
       "  0.19211412966251373,\n",
       "  0.17551523447036743,\n",
       "  0.16309429705142975,\n",
       "  0.15232734382152557,\n",
       "  0.14335739612579346,\n",
       "  0.13520807027816772,\n",
       "  0.1282465159893036,\n",
       "  0.12257514148950577,\n",
       "  0.11699176579713821,\n",
       "  0.11216346174478531,\n",
       "  0.10779833793640137,\n",
       "  0.10398003458976746,\n",
       "  0.10036182403564453,\n",
       "  0.09733829647302628,\n",
       "  0.09398545324802399,\n",
       "  0.091173455119133,\n",
       "  0.08839529007673264,\n",
       "  0.0859035924077034,\n",
       "  0.08347336202859879,\n",
       "  0.08128511160612106,\n",
       "  0.07893350720405579,\n",
       "  0.07701093703508377,\n",
       "  0.07478669285774231,\n",
       "  0.07313431799411774,\n",
       "  0.07125354558229446,\n",
       "  0.06968652456998825,\n",
       "  0.06781032681465149,\n",
       "  0.06633574515581131,\n",
       "  0.06486434489488602,\n",
       "  0.06345811486244202,\n",
       "  0.062099065631628036,\n",
       "  0.06082605943083763,\n",
       "  0.059471700340509415,\n",
       "  0.05829574167728424,\n",
       "  0.05714603140950203,\n",
       "  0.05599129945039749,\n",
       "  0.05488191917538643,\n",
       "  0.053950533270835876,\n",
       "  0.05283646658062935,\n",
       "  0.051863063126802444,\n",
       "  0.051062218844890594,\n",
       "  0.050137877464294434,\n",
       "  0.04919077828526497,\n",
       "  0.04836389422416687,\n",
       "  0.04754180833697319,\n",
       "  0.046692654490470886,\n",
       "  0.04603055119514465,\n",
       "  0.04527987539768219,\n",
       "  0.044517554342746735,\n",
       "  0.04387694597244263,\n",
       "  0.043091028928756714,\n",
       "  0.04239114746451378,\n",
       "  0.04157084599137306,\n",
       "  0.040934108197689056,\n",
       "  0.0401001013815403,\n",
       "  0.03944835439324379,\n",
       "  0.03887289762496948,\n",
       "  0.038194552063941956,\n",
       "  0.03741324692964554,\n",
       "  0.03693573176860809,\n",
       "  0.03612685948610306,\n",
       "  0.03541486710309982,\n",
       "  0.0347822867333889,\n",
       "  0.03418046981096268,\n",
       "  0.033609844744205475,\n",
       "  0.033000897616147995,\n",
       "  0.03247973322868347,\n",
       "  0.031814541667699814,\n",
       "  0.031257469207048416,\n",
       "  0.03066595271229744,\n",
       "  0.030071599408984184,\n",
       "  0.029512040317058563,\n",
       "  0.0289333313703537,\n",
       "  0.0284778643399477,\n",
       "  0.02789362519979477,\n",
       "  0.02731928415596485,\n",
       "  0.026788989081978798,\n",
       "  0.026358410716056824,\n",
       "  0.025970593094825745,\n",
       "  0.025374706834554672,\n",
       "  0.02500171773135662,\n",
       "  0.024514397606253624,\n",
       "  0.02408006601035595,\n",
       "  0.023583445698022842,\n",
       "  0.023263951763510704,\n",
       "  0.022794213145971298,\n",
       "  0.022363435477018356,\n",
       "  0.021962132304906845,\n",
       "  0.02150007337331772,\n",
       "  0.021166646853089333,\n",
       "  0.02072885073721409],\n",
       " 'val_accuracy': [0.5494505763053894,\n",
       "  0.692307710647583,\n",
       "  0.7582417726516724,\n",
       "  0.8131868243217468,\n",
       "  0.8461538553237915,\n",
       "  0.8791208863258362,\n",
       "  0.901098906993866,\n",
       "  0.901098906993866,\n",
       "  0.901098906993866,\n",
       "  0.901098906993866,\n",
       "  0.9120879173278809,\n",
       "  0.9120879173278809,\n",
       "  0.9120879173278809,\n",
       "  0.9120879173278809,\n",
       "  0.9230769276618958,\n",
       "  0.9230769276618958,\n",
       "  0.9230769276618958,\n",
       "  0.9340659379959106,\n",
       "  0.9340659379959106,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9450549483299255,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9670329689979553,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404,\n",
       "  0.9560439586639404],\n",
       " 'val_loss': [0.7586607933044434,\n",
       "  0.6043145060539246,\n",
       "  0.49137040972709656,\n",
       "  0.4104706048965454,\n",
       "  0.35199064016342163,\n",
       "  0.30762743949890137,\n",
       "  0.27456575632095337,\n",
       "  0.2487667053937912,\n",
       "  0.2280542403459549,\n",
       "  0.21115906536579132,\n",
       "  0.19713185727596283,\n",
       "  0.18505512177944183,\n",
       "  0.17466914653778076,\n",
       "  0.16595658659934998,\n",
       "  0.158230721950531,\n",
       "  0.15123958885669708,\n",
       "  0.1447584182024002,\n",
       "  0.13981753587722778,\n",
       "  0.13507011532783508,\n",
       "  0.13078096508979797,\n",
       "  0.12723596394062042,\n",
       "  0.12461183220148087,\n",
       "  0.12217161059379578,\n",
       "  0.11947111785411835,\n",
       "  0.11664212495088577,\n",
       "  0.1145806759595871,\n",
       "  0.11213070899248123,\n",
       "  0.1106385663151741,\n",
       "  0.10912425816059113,\n",
       "  0.1077573373913765,\n",
       "  0.10552670061588287,\n",
       "  0.10394764691591263,\n",
       "  0.10298720747232437,\n",
       "  0.10134477913379669,\n",
       "  0.09947753697633743,\n",
       "  0.0983848050236702,\n",
       "  0.09697543829679489,\n",
       "  0.0958932489156723,\n",
       "  0.09503649920225143,\n",
       "  0.09401869773864746,\n",
       "  0.09270596504211426,\n",
       "  0.09174715727567673,\n",
       "  0.09098833054304123,\n",
       "  0.09041982889175415,\n",
       "  0.0901908278465271,\n",
       "  0.08991063386201859,\n",
       "  0.08972160518169403,\n",
       "  0.08913202583789825,\n",
       "  0.08910685032606125,\n",
       "  0.08795415610074997,\n",
       "  0.08717823028564453,\n",
       "  0.08754643052816391,\n",
       "  0.08729482442140579,\n",
       "  0.08740318566560745,\n",
       "  0.08722058683633804,\n",
       "  0.08700339496135712,\n",
       "  0.08647148311138153,\n",
       "  0.08571995794773102,\n",
       "  0.08600784093141556,\n",
       "  0.08564874529838562,\n",
       "  0.0846744105219841,\n",
       "  0.0844036340713501,\n",
       "  0.08376675099134445,\n",
       "  0.08361107856035233,\n",
       "  0.08289486169815063,\n",
       "  0.08348804712295532,\n",
       "  0.08391085267066956,\n",
       "  0.08288481831550598,\n",
       "  0.0822061076760292,\n",
       "  0.08249416202306747,\n",
       "  0.08282392472028732,\n",
       "  0.08328858017921448,\n",
       "  0.08342286199331284,\n",
       "  0.08344458043575287,\n",
       "  0.08350870013237,\n",
       "  0.08346913009881973,\n",
       "  0.08404602110385895,\n",
       "  0.08403486758470535,\n",
       "  0.08419887721538544,\n",
       "  0.0840635821223259,\n",
       "  0.08380067348480225,\n",
       "  0.08444424718618393,\n",
       "  0.08491518348455429,\n",
       "  0.08472979813814163,\n",
       "  0.08465253561735153,\n",
       "  0.08508395403623581,\n",
       "  0.08554074168205261,\n",
       "  0.085472472012043,\n",
       "  0.08545388281345367,\n",
       "  0.08546268194913864,\n",
       "  0.08568571507930756,\n",
       "  0.0852002501487732,\n",
       "  0.08541073650121689,\n",
       "  0.08587466180324554,\n",
       "  0.08529535681009293,\n",
       "  0.08545321971178055,\n",
       "  0.08543401211500168,\n",
       "  0.08614290505647659,\n",
       "  0.0865531787276268,\n",
       "  0.08532752841711044]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3940592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
