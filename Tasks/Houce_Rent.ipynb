{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4634b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "334cb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "houce_rent = pd.read_csv(\"Rent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25437471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHK</th>\n",
       "      <th>Size</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Area Locality</th>\n",
       "      <th>City</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>N_11</th>\n",
       "      <th>N_12</th>\n",
       "      <th>N_13</th>\n",
       "      <th>N_14</th>\n",
       "      <th>N_15</th>\n",
       "      <th>N_16</th>\n",
       "      <th>N_17</th>\n",
       "      <th>N_18</th>\n",
       "      <th>N_19</th>\n",
       "      <th>N_20</th>\n",
       "      <th>N_21</th>\n",
       "      <th>N_22</th>\n",
       "      <th>Rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>454</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>967.936049</td>\n",
       "      <td>14</td>\n",
       "      <td>1525</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>1758</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>967.936049</td>\n",
       "      <td>10</td>\n",
       "      <td>525</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1888</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BHK         Size  Floor  Area Locality  City  Bathroom  N_11  N_12  N_13  \\\n",
       "0    2  1100.000000    454            220     4         2     0     0     1   \n",
       "1    2   967.936049     14           1525     4         1     0     0     1   \n",
       "2    2  1000.000000     14           1758     4         1     0     0     1   \n",
       "3    2   967.936049     10            525     4         1     0     0     1   \n",
       "4    2   850.000000     10           1888     4         1     0     1     0   \n",
       "\n",
       "   N_14  N_15  N_16  N_17  N_18  N_19  N_20  N_21  N_22   Rent  \n",
       "0     0     0     1     0     1     0     0     0     1  10000  \n",
       "1     0     1     0     0     1     0     0     0     1  20000  \n",
       "2     0     1     0     0     1     0     0     0     1  17000  \n",
       "3     0     0     1     0     1     0     0     0     1  10000  \n",
       "4     0     0     1     1     0     0     0     0     1   7500  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houce_rent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28378485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4727 entries, 0 to 4726\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   BHK            4727 non-null   int64  \n",
      " 1   Size           4727 non-null   float64\n",
      " 2   Floor          4727 non-null   int64  \n",
      " 3   Area Locality  4727 non-null   int64  \n",
      " 4   City           4727 non-null   int64  \n",
      " 5   Bathroom       4727 non-null   int64  \n",
      " 6   N_11           4727 non-null   int64  \n",
      " 7   N_12           4727 non-null   int64  \n",
      " 8   N_13           4727 non-null   int64  \n",
      " 9   N_14           4727 non-null   int64  \n",
      " 10  N_15           4727 non-null   int64  \n",
      " 11  N_16           4727 non-null   int64  \n",
      " 12  N_17           4727 non-null   int64  \n",
      " 13  N_18           4727 non-null   int64  \n",
      " 14  N_19           4727 non-null   int64  \n",
      " 15  N_20           4727 non-null   int64  \n",
      " 16  N_21           4727 non-null   int64  \n",
      " 17  N_22           4727 non-null   int64  \n",
      " 18  Rent           4727 non-null   int64  \n",
      "dtypes: float64(1), int64(18)\n",
      "memory usage: 701.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHK</th>\n",
       "      <th>Size</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Area Locality</th>\n",
       "      <th>City</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>N_11</th>\n",
       "      <th>N_12</th>\n",
       "      <th>N_13</th>\n",
       "      <th>N_14</th>\n",
       "      <th>N_15</th>\n",
       "      <th>N_16</th>\n",
       "      <th>N_17</th>\n",
       "      <th>N_18</th>\n",
       "      <th>N_19</th>\n",
       "      <th>N_20</th>\n",
       "      <th>N_21</th>\n",
       "      <th>N_22</th>\n",
       "      <th>Rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "      <td>4727.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.082082</td>\n",
       "      <td>962.158582</td>\n",
       "      <td>228.930823</td>\n",
       "      <td>1090.191876</td>\n",
       "      <td>2.454411</td>\n",
       "      <td>1.962132</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.482124</td>\n",
       "      <td>0.517453</td>\n",
       "      <td>0.143431</td>\n",
       "      <td>0.473873</td>\n",
       "      <td>0.382695</td>\n",
       "      <td>0.174529</td>\n",
       "      <td>0.725830</td>\n",
       "      <td>0.099640</td>\n",
       "      <td>0.320711</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.679078</td>\n",
       "      <td>33828.690501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.829032</td>\n",
       "      <td>608.358826</td>\n",
       "      <td>162.343589</td>\n",
       "      <td>632.789286</td>\n",
       "      <td>1.787477</td>\n",
       "      <td>0.872806</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.499733</td>\n",
       "      <td>0.499748</td>\n",
       "      <td>0.350549</td>\n",
       "      <td>0.499370</td>\n",
       "      <td>0.486096</td>\n",
       "      <td>0.379604</td>\n",
       "      <td>0.446142</td>\n",
       "      <td>0.299552</td>\n",
       "      <td>0.466799</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.466880</td>\n",
       "      <td>56952.969970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>552.500000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>1629.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>2232.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BHK         Size        Floor  Area Locality         City  \\\n",
       "count  4727.000000  4727.000000  4727.000000    4727.000000  4727.000000   \n",
       "mean      2.082082   962.158582   228.930823    1090.191876     2.454411   \n",
       "std       0.829032   608.358826   162.343589     632.789286     1.787477   \n",
       "min       1.000000    10.000000     0.000000       0.000000     0.000000   \n",
       "25%       2.000000   552.500000    26.000000     550.000000     1.000000   \n",
       "50%       2.000000   850.000000   200.000000    1095.000000     2.000000   \n",
       "75%       3.000000  1200.000000   370.000000    1629.500000     4.000000   \n",
       "max       6.000000  4800.000000   478.000000    2232.000000     5.000000   \n",
       "\n",
       "          Bathroom         N_11         N_12         N_13         N_14  \\\n",
       "count  4727.000000  4727.000000  4727.000000  4727.000000  4727.000000   \n",
       "mean      1.962132     0.000423     0.482124     0.517453     0.143431   \n",
       "std       0.872806     0.020567     0.499733     0.499748     0.350549   \n",
       "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       2.000000     0.000000     1.000000     1.000000     0.000000   \n",
       "max       7.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              N_15         N_16         N_17         N_18         N_19  \\\n",
       "count  4727.000000  4727.000000  4727.000000  4727.000000  4727.000000   \n",
       "mean      0.473873     0.382695     0.174529     0.725830     0.099640   \n",
       "std       0.499370     0.486096     0.379604     0.446142     0.299552   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              N_20         N_21         N_22            Rent  \n",
       "count  4727.000000  4727.000000  4727.000000     4727.000000  \n",
       "mean      0.320711     0.000212     0.679078    33828.690501  \n",
       "std       0.466799     0.014545     0.466880    56952.969970  \n",
       "min       0.000000     0.000000     0.000000     1200.000000  \n",
       "25%       0.000000     0.000000     0.000000    10000.000000  \n",
       "50%       0.000000     0.000000     1.000000    16000.000000  \n",
       "75%       1.000000     0.000000     1.000000    32250.000000  \n",
       "max       1.000000     1.000000     1.000000  1000000.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data information\n",
    "houce_rent.info()\n",
    "houce_rent.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5810b5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BHK              0\n",
       "Size             0\n",
       "Floor            0\n",
       "Area Locality    0\n",
       "City             0\n",
       "Bathroom         0\n",
       "N_11             0\n",
       "N_12             0\n",
       "N_13             0\n",
       "N_14             0\n",
       "N_15             0\n",
       "N_16             0\n",
       "N_17             0\n",
       "N_18             0\n",
       "N_19             0\n",
       "N_20             0\n",
       "N_21             0\n",
       "N_22             0\n",
       "Rent             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houce_rent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5719056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "features=houce_rent.drop(['Rent'],axis=1)\n",
    "target = houce_rent['Rent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7255b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(features)\n",
    "features_scal = scalar.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9368d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(features_scal,target,test_size=0.25,random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0d00ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\mine\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,745</span> (45.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,745\u001b[0m (45.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,745</span> (45.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,745\u001b[0m (45.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(128,  activation=\"relu\", input_shape = x_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"relu\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bf17318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mse\",metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ac214f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1362561024.0000 - mse: 1362561024.0000 - val_loss: 1326544768.0000 - val_mse: 1326544768.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1354669824.0000 - mse: 1354669824.0000 - val_loss: 1332553472.0000 - val_mse: 1332553472.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1353131648.0000 - mse: 1353131648.0000 - val_loss: 1322583680.0000 - val_mse: 1322583680.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1351780992.0000 - mse: 1351780992.0000 - val_loss: 1321856640.0000 - val_mse: 1321856640.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1348965888.0000 - mse: 1348965888.0000 - val_loss: 1321323648.0000 - val_mse: 1321323648.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1349492480.0000 - mse: 1349492480.0000 - val_loss: 1311729792.0000 - val_mse: 1311729792.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1347409408.0000 - mse: 1347409408.0000 - val_loss: 1305130624.0000 - val_mse: 1305130624.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1344855680.0000 - mse: 1344855680.0000 - val_loss: 1306683264.0000 - val_mse: 1306683264.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1342892288.0000 - mse: 1342892288.0000 - val_loss: 1315654784.0000 - val_mse: 1315654784.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1342722688.0000 - mse: 1342722688.0000 - val_loss: 1304654208.0000 - val_mse: 1304654208.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1345917568.0000 - mse: 1345917568.0000 - val_loss: 1309591552.0000 - val_mse: 1309591552.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1338443904.0000 - mse: 1338443904.0000 - val_loss: 1298854016.0000 - val_mse: 1298854016.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1340348032.0000 - mse: 1340348032.0000 - val_loss: 1280300544.0000 - val_mse: 1280300544.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1334954496.0000 - mse: 1334954496.0000 - val_loss: 1296807296.0000 - val_mse: 1296807296.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1331804928.0000 - mse: 1331804928.0000 - val_loss: 1293315840.0000 - val_mse: 1293315840.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1336917760.0000 - mse: 1336917760.0000 - val_loss: 1290792960.0000 - val_mse: 1290792960.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1331234560.0000 - mse: 1331234560.0000 - val_loss: 1289748224.0000 - val_mse: 1289748224.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1327708288.0000 - mse: 1327708288.0000 - val_loss: 1288700416.0000 - val_mse: 1288700416.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1328227712.0000 - mse: 1328227712.0000 - val_loss: 1287337088.0000 - val_mse: 1287337088.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1327212800.0000 - mse: 1327212800.0000 - val_loss: 1276962432.0000 - val_mse: 1276962432.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1324047872.0000 - mse: 1324047872.0000 - val_loss: 1277925888.0000 - val_mse: 1277925888.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1322195712.0000 - mse: 1322195712.0000 - val_loss: 1272486784.0000 - val_mse: 1272486784.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1324760192.0000 - mse: 1324760192.0000 - val_loss: 1276104704.0000 - val_mse: 1276104704.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1321499520.0000 - mse: 1321499520.0000 - val_loss: 1283903616.0000 - val_mse: 1283903616.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1317922688.0000 - mse: 1317922688.0000 - val_loss: 1274015360.0000 - val_mse: 1274015360.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1315879680.0000 - mse: 1315879680.0000 - val_loss: 1268954240.0000 - val_mse: 1268954240.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1312649344.0000 - mse: 1312649344.0000 - val_loss: 1266464128.0000 - val_mse: 1266464128.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1313868032.0000 - mse: 1313868032.0000 - val_loss: 1264183552.0000 - val_mse: 1264183552.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1309447808.0000 - mse: 1309447808.0000 - val_loss: 1263485312.0000 - val_mse: 1263485312.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1308306944.0000 - mse: 1308306944.0000 - val_loss: 1256626688.0000 - val_mse: 1256626688.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1308920064.0000 - mse: 1308920064.0000 - val_loss: 1254818816.0000 - val_mse: 1254818816.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1305018368.0000 - mse: 1305018368.0000 - val_loss: 1253751808.0000 - val_mse: 1253751808.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1302958592.0000 - mse: 1302958592.0000 - val_loss: 1253235840.0000 - val_mse: 1253235840.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1301635456.0000 - mse: 1301635456.0000 - val_loss: 1254968960.0000 - val_mse: 1254968960.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1300739456.0000 - mse: 1300739456.0000 - val_loss: 1241499136.0000 - val_mse: 1241499136.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1298782976.0000 - mse: 1298782976.0000 - val_loss: 1250499328.0000 - val_mse: 1250499328.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1296316416.0000 - mse: 1296316416.0000 - val_loss: 1240771200.0000 - val_mse: 1240771200.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1297756672.0000 - mse: 1297756672.0000 - val_loss: 1246128896.0000 - val_mse: 1246128896.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1291804800.0000 - mse: 1291804800.0000 - val_loss: 1240320512.0000 - val_mse: 1240320512.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1292508032.0000 - mse: 1292508032.0000 - val_loss: 1235642368.0000 - val_mse: 1235642368.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1289065600.0000 - mse: 1289065600.0000 - val_loss: 1233964544.0000 - val_mse: 1233964544.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1287575296.0000 - mse: 1287575296.0000 - val_loss: 1233033728.0000 - val_mse: 1233033728.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1286675584.0000 - mse: 1286675584.0000 - val_loss: 1233419904.0000 - val_mse: 1233419904.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1285984256.0000 - mse: 1285984256.0000 - val_loss: 1227464448.0000 - val_mse: 1227464448.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1284223488.0000 - mse: 1284223488.0000 - val_loss: 1220292224.0000 - val_mse: 1220292224.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1280251392.0000 - mse: 1280251392.0000 - val_loss: 1225586432.0000 - val_mse: 1225586432.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1279504384.0000 - mse: 1279504384.0000 - val_loss: 1216956160.0000 - val_mse: 1216956160.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1278924672.0000 - mse: 1278924672.0000 - val_loss: 1215094528.0000 - val_mse: 1215094528.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1280836352.0000 - mse: 1280836352.0000 - val_loss: 1222992384.0000 - val_mse: 1222992384.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1275356288.0000 - mse: 1275356288.0000 - val_loss: 1217405184.0000 - val_mse: 1217405184.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1272427136.0000 - mse: 1272427136.0000 - val_loss: 1220749824.0000 - val_mse: 1220749824.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1271090176.0000 - mse: 1271090176.0000 - val_loss: 1208382336.0000 - val_mse: 1208382336.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1267631104.0000 - mse: 1267631104.0000 - val_loss: 1207298816.0000 - val_mse: 1207298816.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1269020544.0000 - mse: 1269020544.0000 - val_loss: 1207631360.0000 - val_mse: 1207631360.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1265604480.0000 - mse: 1265604480.0000 - val_loss: 1207694976.0000 - val_mse: 1207694976.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1271626496.0000 - mse: 1271626496.0000 - val_loss: 1182768896.0000 - val_mse: 1182768896.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1260982656.0000 - mse: 1260982656.0000 - val_loss: 1195365760.0000 - val_mse: 1195365760.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1262314880.0000 - mse: 1262314880.0000 - val_loss: 1199675904.0000 - val_mse: 1199675904.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1258981504.0000 - mse: 1258981504.0000 - val_loss: 1194417024.0000 - val_mse: 1194417024.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1257573376.0000 - mse: 1257573376.0000 - val_loss: 1194452992.0000 - val_mse: 1194452992.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1258990848.0000 - mse: 1258990848.0000 - val_loss: 1200470912.0000 - val_mse: 1200470912.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1254124032.0000 - mse: 1254124032.0000 - val_loss: 1191416704.0000 - val_mse: 1191416704.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1253469312.0000 - mse: 1253469312.0000 - val_loss: 1184669184.0000 - val_mse: 1184669184.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1254916992.0000 - mse: 1254916992.0000 - val_loss: 1175333120.0000 - val_mse: 1175333120.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1248227072.0000 - mse: 1248227072.0000 - val_loss: 1182956928.0000 - val_mse: 1182956928.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1247432704.0000 - mse: 1247432704.0000 - val_loss: 1186978560.0000 - val_mse: 1186978560.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1244831744.0000 - mse: 1244831744.0000 - val_loss: 1184639488.0000 - val_mse: 1184639488.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1240804352.0000 - mse: 1240804352.0000 - val_loss: 1156274432.0000 - val_mse: 1156274432.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1244008192.0000 - mse: 1244008192.0000 - val_loss: 1169330688.0000 - val_mse: 1169330688.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1240441856.0000 - mse: 1240441856.0000 - val_loss: 1169353856.0000 - val_mse: 1169353856.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237817216.0000 - mse: 1237817216.0000 - val_loss: 1173185664.0000 - val_mse: 1173185664.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1237806208.0000 - mse: 1237806208.0000 - val_loss: 1172412800.0000 - val_mse: 1172412800.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1236293376.0000 - mse: 1236293376.0000 - val_loss: 1166864384.0000 - val_mse: 1166864384.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1233837440.0000 - mse: 1233837440.0000 - val_loss: 1167025024.0000 - val_mse: 1167025024.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1231952512.0000 - mse: 1231952512.0000 - val_loss: 1168550016.0000 - val_mse: 1168550016.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1229879168.0000 - mse: 1229879168.0000 - val_loss: 1167155456.0000 - val_mse: 1167155456.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1230259200.0000 - mse: 1230259200.0000 - val_loss: 1152523264.0000 - val_mse: 1152523264.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1229186560.0000 - mse: 1229186560.0000 - val_loss: 1155526016.0000 - val_mse: 1155526016.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1227365504.0000 - mse: 1227365504.0000 - val_loss: 1151047552.0000 - val_mse: 1151047552.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1224420608.0000 - mse: 1224420608.0000 - val_loss: 1146779392.0000 - val_mse: 1146779392.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1224976640.0000 - mse: 1224976640.0000 - val_loss: 1155728896.0000 - val_mse: 1155728896.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1222187136.0000 - mse: 1222187136.0000 - val_loss: 1154429056.0000 - val_mse: 1154429056.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1223929216.0000 - mse: 1223929216.0000 - val_loss: 1151006976.0000 - val_mse: 1151006976.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1217299712.0000 - mse: 1217299712.0000 - val_loss: 1147280000.0000 - val_mse: 1147280000.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1218273024.0000 - mse: 1218273024.0000 - val_loss: 1141042176.0000 - val_mse: 1141042176.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1215165056.0000 - mse: 1215165056.0000 - val_loss: 1136899968.0000 - val_mse: 1136899968.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1214492032.0000 - mse: 1214492032.0000 - val_loss: 1145487488.0000 - val_mse: 1145487488.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1208039552.0000 - mse: 1208039552.0000 - val_loss: 1134191872.0000 - val_mse: 1134191872.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1209063552.0000 - mse: 1209063552.0000 - val_loss: 1127407744.0000 - val_mse: 1127407744.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1207903872.0000 - mse: 1207903872.0000 - val_loss: 1131756800.0000 - val_mse: 1131756800.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1207237888.0000 - mse: 1207237888.0000 - val_loss: 1139995904.0000 - val_mse: 1139995904.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1204156032.0000 - mse: 1204156032.0000 - val_loss: 1123335808.0000 - val_mse: 1123335808.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1199630720.0000 - mse: 1199630720.0000 - val_loss: 1132758528.0000 - val_mse: 1132758528.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1203003264.0000 - mse: 1203003264.0000 - val_loss: 1137897600.0000 - val_mse: 1137897600.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1200578176.0000 - mse: 1200578176.0000 - val_loss: 1140444032.0000 - val_mse: 1140444032.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1204537344.0000 - mse: 1204537344.0000 - val_loss: 1127113216.0000 - val_mse: 1127113216.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1193255296.0000 - mse: 1193255296.0000 - val_loss: 1126900352.0000 - val_mse: 1126900352.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1191787904.0000 - mse: 1191787904.0000 - val_loss: 1131395328.0000 - val_mse: 1131395328.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1189155840.0000 - mse: 1189155840.0000 - val_loss: 1124855424.0000 - val_mse: 1124855424.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1188533504.0000 - mse: 1188533504.0000 - val_loss: 1117366528.0000 - val_mse: 1117366528.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fa873ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "    Actual     Predicted\n",
      "0    11000  15397.972656\n",
      "1    12000  17957.761719\n",
      "2     7000  11005.607422\n",
      "3    44000  37041.683594\n",
      "4    12500  13193.877930\n",
      "5    15000  15901.228516\n",
      "6    25000  71299.710938\n",
      "7    15000  16265.936523\n",
      "8    11000  10782.912109\n",
      "9    13000  17572.773438\n",
      "10    3000   7958.627930\n",
      "11   17000  10405.142578\n",
      "12    8000  13027.730469\n",
      "13    9300  14431.700195\n",
      "14  130000  93429.898438\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "df_data = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred.flatten()})\n",
    "print(df_data.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a17379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
