{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29614844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df605ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "stroke_data = pd.read_csv(\"stroke.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7badad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9722 entries, 0 to 9721\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             9722 non-null   float64\n",
      " 1   age                9722 non-null   float64\n",
      " 2   hypertension       9722 non-null   float64\n",
      " 3   heart_disease      9722 non-null   float64\n",
      " 4   ever_married       9722 non-null   float64\n",
      " 5   work_type          9722 non-null   float64\n",
      " 6   Residence_type     9722 non-null   float64\n",
      " 7   avg_glucose_level  9722 non-null   float64\n",
      " 8   bmi                9722 non-null   float64\n",
      " 9   smoking_status     9722 non-null   float64\n",
      " 10  stroke             9722 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 835.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "      <td>9722.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.213367</td>\n",
       "      <td>0.673399</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>0.113321</td>\n",
       "      <td>0.769813</td>\n",
       "      <td>0.529794</td>\n",
       "      <td>0.523473</td>\n",
       "      <td>0.292612</td>\n",
       "      <td>0.219453</td>\n",
       "      <td>0.478090</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.242441</td>\n",
       "      <td>0.268022</td>\n",
       "      <td>0.378565</td>\n",
       "      <td>0.315993</td>\n",
       "      <td>0.419034</td>\n",
       "      <td>0.234394</td>\n",
       "      <td>0.498976</td>\n",
       "      <td>0.247178</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.330446</td>\n",
       "      <td>0.500026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.251364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.743652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192411</td>\n",
       "      <td>0.212981</td>\n",
       "      <td>0.591332</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.899620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416104</td>\n",
       "      <td>0.254539</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age  hypertension  heart_disease  ever_married  \\\n",
       "count  9722.000000  9722.000000   9722.000000    9722.000000   9722.000000   \n",
       "mean      0.213367     0.673399      0.173676       0.113321      0.769813   \n",
       "std       0.242441     0.268022      0.378565       0.315993      0.419034   \n",
       "min       0.000000     0.000000      0.000000       0.000000      0.000000   \n",
       "25%       0.000000     0.511719      0.000000       0.000000      1.000000   \n",
       "50%       0.000000     0.743652      0.000000       0.000000      1.000000   \n",
       "75%       0.500000     0.899620      0.000000       0.000000      1.000000   \n",
       "max       1.000000     1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "         work_type  Residence_type  avg_glucose_level          bmi  \\\n",
       "count  9722.000000     9722.000000        9722.000000  9722.000000   \n",
       "mean      0.529794        0.523473           0.292612     0.219453   \n",
       "std       0.234394        0.498976           0.247178     0.074600   \n",
       "min       0.000000        0.000000           0.000000     0.000000   \n",
       "25%       0.500000        0.000000           0.112887     0.175258   \n",
       "50%       0.500000        1.000000           0.192411     0.212981   \n",
       "75%       0.676584        1.000000           0.416104     0.254539   \n",
       "max       1.000000        1.000000           1.000000     1.000000   \n",
       "\n",
       "       smoking_status       stroke  \n",
       "count     9722.000000  9722.000000  \n",
       "mean         0.478090     0.500000  \n",
       "std          0.330446     0.500026  \n",
       "min          0.000000     0.000000  \n",
       "25%          0.251364     0.000000  \n",
       "50%          0.591332     0.500000  \n",
       "75%          0.666667     1.000000  \n",
       "max          1.000000     1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data information \n",
    "stroke_data.info()\n",
    "stroke_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66f7b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_data.isnull().sum()\n",
    "## data is cleaned  and scaled it looks ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "174648fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "stroke_features = stroke_data.drop([\"stroke\"],axis=1)\n",
    "stroke_target = stroke_data[\"stroke\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(stroke_features,stroke_target,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aca46833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\mine\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,777</span> (46.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,777\u001b[0m (46.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,777</span> (46.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,777\u001b[0m (46.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(128 , activation='relu',input_shape = x_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(64 , activation='relu'))\n",
    "model.add(keras.layers.Dense(32 , activation='relu'))\n",
    "model.add(keras.layers.Dense(1 , activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "471ec8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"Adam\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6929f0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7502 - auc: 0.8235 - loss: 0.5225 - val_accuracy: 0.7988 - val_auc: 0.8699 - val_loss: 0.4392\n",
      "Epoch 2/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7959 - auc: 0.8658 - loss: 0.4450 - val_accuracy: 0.8014 - val_auc: 0.8775 - val_loss: 0.4270\n",
      "Epoch 3/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7978 - auc: 0.8705 - loss: 0.4369 - val_accuracy: 0.8001 - val_auc: 0.8801 - val_loss: 0.4193\n",
      "Epoch 4/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8066 - auc: 0.8780 - loss: 0.4231 - val_accuracy: 0.8033 - val_auc: 0.8823 - val_loss: 0.4143\n",
      "Epoch 5/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8057 - auc: 0.8813 - loss: 0.4176 - val_accuracy: 0.8130 - val_auc: 0.8857 - val_loss: 0.4107\n",
      "Epoch 6/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8151 - auc: 0.8867 - loss: 0.4074 - val_accuracy: 0.8168 - val_auc: 0.8867 - val_loss: 0.4042\n",
      "Epoch 7/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8169 - auc: 0.8903 - loss: 0.4019 - val_accuracy: 0.8111 - val_auc: 0.8890 - val_loss: 0.4000\n",
      "Epoch 8/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8176 - auc: 0.8917 - loss: 0.3987 - val_accuracy: 0.8207 - val_auc: 0.8979 - val_loss: 0.3852\n",
      "Epoch 9/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8209 - auc: 0.8960 - loss: 0.3897 - val_accuracy: 0.8278 - val_auc: 0.8983 - val_loss: 0.3822\n",
      "Epoch 10/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8270 - auc: 0.9004 - loss: 0.3797 - val_accuracy: 0.8246 - val_auc: 0.8986 - val_loss: 0.3857\n",
      "Epoch 11/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8286 - auc: 0.9038 - loss: 0.3745 - val_accuracy: 0.8290 - val_auc: 0.9023 - val_loss: 0.3747\n",
      "Epoch 12/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8317 - auc: 0.9064 - loss: 0.3679 - val_accuracy: 0.8213 - val_auc: 0.9046 - val_loss: 0.3897\n",
      "Epoch 13/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - auc: 0.9114 - loss: 0.3589 - val_accuracy: 0.8207 - val_auc: 0.9069 - val_loss: 0.3742\n",
      "Epoch 14/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8421 - auc: 0.9142 - loss: 0.3519 - val_accuracy: 0.8323 - val_auc: 0.9135 - val_loss: 0.3509\n",
      "Epoch 15/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8431 - auc: 0.9156 - loss: 0.3486 - val_accuracy: 0.8432 - val_auc: 0.9144 - val_loss: 0.3482\n",
      "Epoch 16/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8441 - auc: 0.9193 - loss: 0.3404 - val_accuracy: 0.8432 - val_auc: 0.9175 - val_loss: 0.3488\n",
      "Epoch 17/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8487 - auc: 0.9213 - loss: 0.3360 - val_accuracy: 0.8419 - val_auc: 0.9187 - val_loss: 0.3357\n",
      "Epoch 18/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8463 - auc: 0.9211 - loss: 0.3352 - val_accuracy: 0.8586 - val_auc: 0.9211 - val_loss: 0.3384\n",
      "Epoch 19/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8523 - auc: 0.9237 - loss: 0.3299 - val_accuracy: 0.8470 - val_auc: 0.9211 - val_loss: 0.3470\n",
      "Epoch 20/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8550 - auc: 0.9270 - loss: 0.3228 - val_accuracy: 0.8535 - val_auc: 0.9214 - val_loss: 0.3305\n",
      "Epoch 21/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - auc: 0.9308 - loss: 0.3131 - val_accuracy: 0.8535 - val_auc: 0.9294 - val_loss: 0.3224\n",
      "Epoch 22/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8632 - auc: 0.9307 - loss: 0.3125 - val_accuracy: 0.8509 - val_auc: 0.9283 - val_loss: 0.3209\n",
      "Epoch 23/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8622 - auc: 0.9322 - loss: 0.3087 - val_accuracy: 0.8586 - val_auc: 0.9309 - val_loss: 0.3146\n",
      "Epoch 24/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8671 - auc: 0.9341 - loss: 0.3038 - val_accuracy: 0.8625 - val_auc: 0.9286 - val_loss: 0.3160\n",
      "Epoch 25/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8664 - auc: 0.9352 - loss: 0.3012 - val_accuracy: 0.8708 - val_auc: 0.9351 - val_loss: 0.3086\n",
      "Epoch 26/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8682 - auc: 0.9378 - loss: 0.2976 - val_accuracy: 0.8490 - val_auc: 0.9326 - val_loss: 0.3183\n",
      "Epoch 27/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8680 - auc: 0.9384 - loss: 0.2939 - val_accuracy: 0.8522 - val_auc: 0.9289 - val_loss: 0.3311\n",
      "Epoch 28/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8724 - auc: 0.9401 - loss: 0.2886 - val_accuracy: 0.8676 - val_auc: 0.9388 - val_loss: 0.2932\n",
      "Epoch 29/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8745 - auc: 0.9404 - loss: 0.2869 - val_accuracy: 0.8676 - val_auc: 0.9343 - val_loss: 0.3127\n",
      "Epoch 30/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8788 - auc: 0.9457 - loss: 0.2764 - val_accuracy: 0.8721 - val_auc: 0.9416 - val_loss: 0.2924\n",
      "Epoch 31/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8783 - auc: 0.9435 - loss: 0.2792 - val_accuracy: 0.8779 - val_auc: 0.9388 - val_loss: 0.2903\n",
      "Epoch 32/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8791 - auc: 0.9459 - loss: 0.2749 - val_accuracy: 0.8670 - val_auc: 0.9439 - val_loss: 0.2868\n",
      "Epoch 33/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8838 - auc: 0.9476 - loss: 0.2696 - val_accuracy: 0.8734 - val_auc: 0.9421 - val_loss: 0.2885\n",
      "Epoch 34/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - auc: 0.9482 - loss: 0.2687 - val_accuracy: 0.8772 - val_auc: 0.9464 - val_loss: 0.2748\n",
      "Epoch 35/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8844 - auc: 0.9474 - loss: 0.2704 - val_accuracy: 0.8715 - val_auc: 0.9432 - val_loss: 0.2808\n",
      "Epoch 36/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8864 - auc: 0.9492 - loss: 0.2646 - val_accuracy: 0.8824 - val_auc: 0.9448 - val_loss: 0.2872\n",
      "Epoch 37/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8884 - auc: 0.9527 - loss: 0.2562 - val_accuracy: 0.8740 - val_auc: 0.9417 - val_loss: 0.2851\n",
      "Epoch 38/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8917 - auc: 0.9511 - loss: 0.2584 - val_accuracy: 0.8850 - val_auc: 0.9474 - val_loss: 0.2732\n",
      "Epoch 39/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8900 - auc: 0.9520 - loss: 0.2562 - val_accuracy: 0.8850 - val_auc: 0.9486 - val_loss: 0.2878\n",
      "Epoch 40/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8936 - auc: 0.9543 - loss: 0.2500 - val_accuracy: 0.8882 - val_auc: 0.9468 - val_loss: 0.2725\n",
      "Epoch 41/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8954 - auc: 0.9549 - loss: 0.2462 - val_accuracy: 0.8856 - val_auc: 0.9515 - val_loss: 0.2624\n",
      "Epoch 42/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8979 - auc: 0.9571 - loss: 0.2434 - val_accuracy: 0.8907 - val_auc: 0.9487 - val_loss: 0.2676\n",
      "Epoch 43/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9018 - auc: 0.9574 - loss: 0.2404 - val_accuracy: 0.8811 - val_auc: 0.9490 - val_loss: 0.2714\n",
      "Epoch 44/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - auc: 0.9571 - loss: 0.2410 - val_accuracy: 0.8946 - val_auc: 0.9542 - val_loss: 0.2590\n",
      "Epoch 45/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - auc: 0.9565 - loss: 0.2448 - val_accuracy: 0.9004 - val_auc: 0.9535 - val_loss: 0.2577\n",
      "Epoch 46/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8995 - auc: 0.9589 - loss: 0.2361 - val_accuracy: 0.9068 - val_auc: 0.9581 - val_loss: 0.2449\n",
      "Epoch 47/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9023 - auc: 0.9598 - loss: 0.2358 - val_accuracy: 0.8888 - val_auc: 0.9487 - val_loss: 0.2672\n",
      "Epoch 48/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9045 - auc: 0.9602 - loss: 0.2335 - val_accuracy: 0.8920 - val_auc: 0.9504 - val_loss: 0.2728\n",
      "Epoch 49/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9098 - auc: 0.9615 - loss: 0.2279 - val_accuracy: 0.8959 - val_auc: 0.9535 - val_loss: 0.2585\n",
      "Epoch 50/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9047 - auc: 0.9629 - loss: 0.2260 - val_accuracy: 0.8805 - val_auc: 0.9506 - val_loss: 0.2905\n",
      "Epoch 51/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9063 - auc: 0.9611 - loss: 0.2301 - val_accuracy: 0.9068 - val_auc: 0.9582 - val_loss: 0.2408\n",
      "Epoch 52/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9085 - auc: 0.9647 - loss: 0.2194 - val_accuracy: 0.8952 - val_auc: 0.9584 - val_loss: 0.2482\n",
      "Epoch 53/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9180 - auc: 0.9674 - loss: 0.2120 - val_accuracy: 0.8991 - val_auc: 0.9577 - val_loss: 0.2411\n",
      "Epoch 54/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9148 - auc: 0.9657 - loss: 0.2147 - val_accuracy: 0.8772 - val_auc: 0.9603 - val_loss: 0.2736\n",
      "Epoch 55/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9129 - auc: 0.9645 - loss: 0.2186 - val_accuracy: 0.9107 - val_auc: 0.9605 - val_loss: 0.2354\n",
      "Epoch 56/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9126 - auc: 0.9657 - loss: 0.2157 - val_accuracy: 0.8888 - val_auc: 0.9567 - val_loss: 0.2755\n",
      "Epoch 57/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - auc: 0.9678 - loss: 0.2103 - val_accuracy: 0.9010 - val_auc: 0.9575 - val_loss: 0.2489\n",
      "Epoch 58/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9134 - auc: 0.9661 - loss: 0.2124 - val_accuracy: 0.8940 - val_auc: 0.9579 - val_loss: 0.2637\n",
      "Epoch 59/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9180 - auc: 0.9691 - loss: 0.2042 - val_accuracy: 0.9017 - val_auc: 0.9562 - val_loss: 0.2485\n",
      "Epoch 60/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - auc: 0.9684 - loss: 0.2078 - val_accuracy: 0.9042 - val_auc: 0.9614 - val_loss: 0.2335\n",
      "Epoch 61/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9195 - auc: 0.9718 - loss: 0.1969 - val_accuracy: 0.9049 - val_auc: 0.9628 - val_loss: 0.2297\n",
      "Epoch 62/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9177 - auc: 0.9692 - loss: 0.2045 - val_accuracy: 0.9197 - val_auc: 0.9654 - val_loss: 0.2216\n",
      "Epoch 63/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9272 - auc: 0.9745 - loss: 0.1871 - val_accuracy: 0.9210 - val_auc: 0.9623 - val_loss: 0.2252\n",
      "Epoch 64/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9199 - auc: 0.9715 - loss: 0.1990 - val_accuracy: 0.9145 - val_auc: 0.9634 - val_loss: 0.2250\n",
      "Epoch 65/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9288 - auc: 0.9746 - loss: 0.1863 - val_accuracy: 0.9126 - val_auc: 0.9632 - val_loss: 0.2307\n",
      "Epoch 66/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9261 - auc: 0.9736 - loss: 0.1876 - val_accuracy: 0.9177 - val_auc: 0.9666 - val_loss: 0.2243\n",
      "Epoch 67/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9236 - auc: 0.9724 - loss: 0.1920 - val_accuracy: 0.9094 - val_auc: 0.9614 - val_loss: 0.2357\n",
      "Epoch 68/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9275 - auc: 0.9731 - loss: 0.1878 - val_accuracy: 0.9087 - val_auc: 0.9611 - val_loss: 0.2387\n",
      "Epoch 69/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9294 - auc: 0.9745 - loss: 0.1843 - val_accuracy: 0.8978 - val_auc: 0.9578 - val_loss: 0.2552\n",
      "Epoch 70/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9285 - auc: 0.9756 - loss: 0.1810 - val_accuracy: 0.9126 - val_auc: 0.9642 - val_loss: 0.2259\n",
      "Epoch 71/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9301 - auc: 0.9768 - loss: 0.1756 - val_accuracy: 0.9210 - val_auc: 0.9686 - val_loss: 0.2079\n",
      "Epoch 72/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9290 - auc: 0.9767 - loss: 0.1788 - val_accuracy: 0.9274 - val_auc: 0.9678 - val_loss: 0.2169\n",
      "Epoch 73/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9336 - auc: 0.9773 - loss: 0.1742 - val_accuracy: 0.9184 - val_auc: 0.9624 - val_loss: 0.2392\n",
      "Epoch 74/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9318 - auc: 0.9779 - loss: 0.1724 - val_accuracy: 0.9332 - val_auc: 0.9692 - val_loss: 0.2045\n",
      "Epoch 75/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9299 - auc: 0.9786 - loss: 0.1731 - val_accuracy: 0.9261 - val_auc: 0.9680 - val_loss: 0.2156\n",
      "Epoch 76/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - auc: 0.9780 - loss: 0.1686 - val_accuracy: 0.9184 - val_auc: 0.9621 - val_loss: 0.2339\n",
      "Epoch 77/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9341 - auc: 0.9786 - loss: 0.1697 - val_accuracy: 0.9023 - val_auc: 0.9629 - val_loss: 0.2453\n",
      "Epoch 78/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9341 - auc: 0.9793 - loss: 0.1681 - val_accuracy: 0.9210 - val_auc: 0.9654 - val_loss: 0.2195\n",
      "Epoch 79/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9373 - auc: 0.9791 - loss: 0.1666 - val_accuracy: 0.9274 - val_auc: 0.9652 - val_loss: 0.2194\n",
      "Epoch 80/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9389 - auc: 0.9802 - loss: 0.1608 - val_accuracy: 0.9267 - val_auc: 0.9686 - val_loss: 0.2129\n",
      "Epoch 81/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9365 - auc: 0.9810 - loss: 0.1623 - val_accuracy: 0.8914 - val_auc: 0.9439 - val_loss: 0.3049\n",
      "Epoch 82/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9309 - auc: 0.9771 - loss: 0.1770 - val_accuracy: 0.9229 - val_auc: 0.9680 - val_loss: 0.2156\n",
      "Epoch 83/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9365 - auc: 0.9801 - loss: 0.1626 - val_accuracy: 0.9177 - val_auc: 0.9672 - val_loss: 0.2211\n",
      "Epoch 84/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9408 - auc: 0.9829 - loss: 0.1535 - val_accuracy: 0.9203 - val_auc: 0.9641 - val_loss: 0.2328\n",
      "Epoch 85/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9389 - auc: 0.9816 - loss: 0.1582 - val_accuracy: 0.9267 - val_auc: 0.9685 - val_loss: 0.2149\n",
      "Epoch 86/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9445 - auc: 0.9835 - loss: 0.1484 - val_accuracy: 0.9280 - val_auc: 0.9652 - val_loss: 0.2203\n",
      "Epoch 87/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - auc: 0.9789 - loss: 0.1676 - val_accuracy: 0.9274 - val_auc: 0.9701 - val_loss: 0.2080\n",
      "Epoch 88/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9437 - auc: 0.9842 - loss: 0.1451 - val_accuracy: 0.9145 - val_auc: 0.9606 - val_loss: 0.2364\n",
      "Epoch 89/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9476 - auc: 0.9843 - loss: 0.1448 - val_accuracy: 0.9267 - val_auc: 0.9668 - val_loss: 0.2163\n",
      "Epoch 90/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - auc: 0.9821 - loss: 0.1586 - val_accuracy: 0.9100 - val_auc: 0.9683 - val_loss: 0.2372\n",
      "Epoch 91/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9447 - auc: 0.9834 - loss: 0.1472 - val_accuracy: 0.9210 - val_auc: 0.9681 - val_loss: 0.2184\n",
      "Epoch 92/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - auc: 0.9848 - loss: 0.1423 - val_accuracy: 0.9261 - val_auc: 0.9672 - val_loss: 0.2169\n",
      "Epoch 93/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - auc: 0.9816 - loss: 0.1582 - val_accuracy: 0.9235 - val_auc: 0.9643 - val_loss: 0.2331\n",
      "Epoch 94/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - auc: 0.9854 - loss: 0.1399 - val_accuracy: 0.9261 - val_auc: 0.9666 - val_loss: 0.2245\n",
      "Epoch 95/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9416 - auc: 0.9825 - loss: 0.1536 - val_accuracy: 0.9338 - val_auc: 0.9708 - val_loss: 0.2082\n",
      "Epoch 96/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - auc: 0.9838 - loss: 0.1473 - val_accuracy: 0.9139 - val_auc: 0.9638 - val_loss: 0.2510\n",
      "Epoch 97/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9470 - auc: 0.9851 - loss: 0.1394 - val_accuracy: 0.9332 - val_auc: 0.9707 - val_loss: 0.2019\n",
      "Epoch 98/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - auc: 0.9864 - loss: 0.1350 - val_accuracy: 0.9312 - val_auc: 0.9708 - val_loss: 0.2009\n",
      "Epoch 99/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9465 - auc: 0.9859 - loss: 0.1385 - val_accuracy: 0.9075 - val_auc: 0.9643 - val_loss: 0.2524\n",
      "Epoch 100/100\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - auc: 0.9853 - loss: 0.1415 - val_accuracy: 0.9216 - val_auc: 0.9638 - val_loss: 0.2359\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abbff1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86       975\n",
      "           1       0.80      0.99      0.89       970\n",
      "\n",
      "    accuracy                           0.87      1945\n",
      "   macro avg       0.90      0.87      0.87      1945\n",
      "weighted avg       0.90      0.87      0.87      1945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > .05).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396a177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
